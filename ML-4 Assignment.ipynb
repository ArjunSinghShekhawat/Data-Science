{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e3c48-d9d0-423c-b633-1e21ca5cc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9f186-2b9a-4ea5-a7aa-c2504da41ee6",
   "metadata": {},
   "source": [
    "Q1. Lasso Regression adds L1 regularization to linear regression, promoting sparsity. It differs by shrinking coefficients to zero for feature selection.\n",
    "\n",
    "Q2. Lasso's advantage is automatic feature selection, making it valuable when dealing with a large number of features.\n",
    "\n",
    "Q3. Lasso coefficients indicate variable importance; non-zero values signify selected features, while zero indicates excluded ones.\n",
    "\n",
    "Q4. The tuning parameter in Lasso is lambda (Î±). Higher values promote sparsity, effectively selecting fewer features, impacting model complexity and bias.\n",
    "\n",
    "Q5. Lasso can handle non-linearity to some extent but may not be as effective as methods explicitly designed for non-linear problems.\n",
    "\n",
    "Q6. Ridge adds L2 regularization to preserve correlated variables, while Lasso uses L1 regularization for feature selection.\n",
    "\n",
    "Q7. Yes, Lasso can handle multicollinearity by automatically choosing one feature over others, effectively addressing the issue.\n",
    "\n",
    "Q8. Optimal lambda in Lasso is often selected using cross-validation, balancing between sparsity and model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
