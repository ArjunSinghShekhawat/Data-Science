{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59b838-b632-476f-9b30-c4947942b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. Explain the difference between linear regression and logistic regression models. Provide an example of\n",
    "a scenario where logistic regression would be more appropriate.\n",
    "Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression\n",
    "model?\n",
    "Q5. What are some common techniques for feature selection in logistic regression? How do these\n",
    "techniques help improve the model's performance?\n",
    "Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing\n",
    "with class imbalance?\n",
    "Q7. Can you discuss some common issues and challenges that may arise when implementing logistic\n",
    "regression, and how they can be addressed? For example, what can be done if there is multicollinearity\n",
    "among the independent variables?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a49eb1f-51cb-40a8-8568-d74add9eced4",
   "metadata": {},
   "source": [
    "Q1. Linear regression predicts continuous outcomes, while logistic regression is for binary classification (e.g., spam or not). Logistic regression suits scenarios where you need to predict probabilities or make classification decisions.\n",
    "\n",
    "Q2. Logistic regression uses the log-likelihood cost function, optimized with techniques like gradient descent, to find the best model parameters.\n",
    "\n",
    "Q3. Regularization adds penalty terms to the cost function, controlling the complexity of the model and preventing overfitting in logistic regression.\n",
    "\n",
    "Q4. The ROC curve (Receiver Operating Characteristic) evaluates the trade-off between true positive rate (sensitivity) and false positive rate. A larger AUC (area under the curve) indicates better model performance.\n",
    "\n",
    "Q5. Common feature selection techniques in logistic regression include stepwise selection and L1 regularization (Lasso). These techniques help improve model performance by removing less relevant features.\n",
    "\n",
    "Q6. Handling imbalanced datasets can involve methods like oversampling the minority class, undersampling the majority class, or using algorithms like SMOTE to balance the dataset.\n",
    "\n",
    "Q7. Challenges in logistic regression include multicollinearity. It can be addressed by removing correlated variables or using regularization techniques like L1 or L2 to prevent overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
